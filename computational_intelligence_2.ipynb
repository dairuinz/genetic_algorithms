{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"computational_intelligence_2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOagG5f9vuo9HpYPYtxduHV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('train-data.dat', sep=',', header=None)\n","df.columns = ['sentence']\n","df['sentence'] = df['sentence'].str.replace('<.*?>', '', regex=True)  # deletes <int>\n","# print(df.head())\n","df = df[0:1000]\n","df.head()\n","\n","vocab = pd.read_csv('vocabs.txt', sep=',', header=None)\n","vocab.columns = ['word', 'id']\n","\n","sentences = pd.read_csv('train-data.dat', sep=',', header=None)\n","sentences.head()\n","\n","com = []\n","for line in df.sentence:\n","    sen = ''\n","    for word in line.split():\n","      for id in vocab.id:\n","        if int(word) == int(id):\n","          sen = sen + ' ' + str(vocab.word[id]) \n","    # print(sen)\n","    com.append(sen)"],"metadata":{"id":"UhWupimFKO0P","executionInfo":{"status":"ok","timestamp":1653584443695,"user_tz":-180,"elapsed":370442,"user":{"displayName":"Orestis_M","userId":"00362259064081137390"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","import numpy as np\n","\n","tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n","tfidf_vectors = tfidf_vectorizer.fit_transform(com)\n","\n","tfidf = tfidf_vectors.todense()\n","# TFIDF of words not in the doc will be 0, so replace them with nan\n","tfidf[tfidf == 0] = np.nan\n","# Use nanmean of numpy which will ignore nan while calculating the mean\n","means = np.nanmean(tfidf, axis=0)\n","# convert it into a dictionary for later lookup\n","means = dict(zip(tfidf_vectorizer.get_feature_names(), means.tolist()[0]))\n","\n","tfidf = tfidf_vectors.todense()\n","# Argsort the full TFIDF dense vector\n","ordered = np.argsort(tfidf*-1)\n","words = tfidf_vectorizer.get_feature_names()\n","\n","# top_k = 5\n","# for i, doc in enumerate(com):\n","#     result = {}\n","#     # Pick top_k from each argsorted matrix for each doc\n","#     for t in range(top_k):\n","#         # Pick the top k word, find its average tfidf from the\n","#         # precomputed dictionary using nanmean and save it to later use\n","#         result[words[ordered[i,t]]] = means[words[ordered[i,t]]]\n","#     # print (result)\n","\n","# means\n","\n","# from collections import Counter \n","\n","# means = dict(Counter(means).most_common(1000))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Tf6MwRoLe2F","executionInfo":{"status":"ok","timestamp":1653584445340,"user_tz":-180,"elapsed":1655,"user":{"displayName":"Orestis_M","userId":"00362259064081137390"}},"outputId":"f2968289-260a-4fc3-9746-7c228fbf826f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","source":["li = [[]]\n","\n","for key in means:\n","  li.append([key, means[key]])\n","\n","li.pop(0)\n","li[:5]\n","\n","df2 = pd.DataFrame(li)\n","# df2 = df2.transpose()\n","df2.head()\n","\n","tfidf_sc = df2[1]\n","print(tfidf_sc)\n","tfidf_len = len(tfidf_sc)\n","print(tfidf_len)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cbxxhaKg3Ckv","executionInfo":{"status":"ok","timestamp":1653584445343,"user_tz":-180,"elapsed":25,"user":{"displayName":"Orestis_M","userId":"00362259064081137390"}},"outputId":"492c7a25-806d-471e-b815-bf6d370caadb"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["0       0.180064\n","1       0.105520\n","2       0.098096\n","3       0.163385\n","4       0.138688\n","          ...   \n","6848    0.110620\n","6849    0.151121\n","6850    0.124428\n","6851    0.184492\n","6852    0.223934\n","Name: 1, Length: 6853, dtype: float64\n","6853\n"]}]},{"cell_type":"code","source":["# !pip install deap\n","\n","import random\n","\n","import matplotlib.pyplot as plt\n","from deap import base\n","from deap import creator\n","from deap import tools\n","\n","POP_SIZE = 20\n","P_CROSSOVER = 0.6\n","P_MUTATION = 0.01\n","MAX_GENERATIONS = 200\n","GENERATIONS_EXIT = 20  # state the number of generations in which maxFitness remains the same,  for stopping condition\n","\n","\n","creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","creator.create(\"Individual\", list, fitness=creator.FitnessMax)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GT28b2Nu78go","executionInfo":{"status":"ok","timestamp":1653582141607,"user_tz":-180,"elapsed":5983,"user":{"displayName":"Orestis_M","userId":"00362259064081137390"}},"outputId":"52b0e977-c735-4c5e-a05d-282422293485"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting deap\n","  Downloading deap-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.21.6)\n","Installing collected packages: deap\n","Successfully installed deap-1.3.1\n"]}]},{"cell_type":"code","source":["def pop_generator(POP_SIZE):\n","  li = [[random.randint(0,1) for x in range(tfidf_len)] for y in range(POP_SIZE)] \n","\n","\n","  for i in range(len(li)):\n","    ones = 0\n","    for j in li[i]:\n","      if j==1:\n","        ones+=1\n","    # if ones<1000:\n","    while ones<4:\n","      print(ones)\n","      print(li[i])\n","      li[i] = [random.randint(0,1) for x in range(10)]\n","      print(li[i])\n","\n","\n","  li_df = pd.DataFrame(li)\n","  li_df.head()\n","\n","  return li"],"metadata":{"id":"J_Mb5VSK4V2a","executionInfo":{"status":"ok","timestamp":1653584692999,"user_tz":-180,"elapsed":8,"user":{"displayName":"Orestis_M","userId":"00362259064081137390"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# tfidf_sc\n","# df2.columns=['word', 'importance']\n","# df2.head(5)\n","\n","def evaluation_function(individual):  \n","  a = np.mean(individual)\n","  return a"],"metadata":{"id":"stKTpQ8SWRM_","executionInfo":{"status":"ok","timestamp":1653586268608,"user_tz":-180,"elapsed":10,"user":{"displayName":"Orestis_M","userId":"00362259064081137390"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["def set_fitness(population):\n","    ... # set fitness of non-dominant individuals to 0\n","    return population"],"metadata":{"id":"XddGtW9YZeQr","executionInfo":{"status":"ok","timestamp":1653584779146,"user_tz":-180,"elapsed":816,"user":{"displayName":"Orestis_M","userId":"00362259064081137390"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["tbx = base.Toolbox()\n","\n","INDIVIDUAL_SIZE = 20\n","\n","tbx.register(\"attr_int\", random.randint, 0, 1)\n","tbx.register(\"individual\", tools.initRepeat, creator.Individual, tbx.attr_int, n=INDIVIDUAL_SIZE)\n","tbx.register(\"population\", tools.initRepeat, list, tbx.individual)\n","tbx.register(\"evaluate\", evaluation_function)\n","# tbx.register(\"mate\", tools.cxOnePoint)\n","# tbx.register(\"mutate\", tools.mutFlipBit, indpb=0.01)\n","# tbx.register(\"select\", tools.selTournament, tournsize=5)"],"metadata":{"id":"9KLRlpzO06CJ","executionInfo":{"status":"ok","timestamp":1653586272293,"user_tz":-180,"elapsed":369,"user":{"displayName":"Orestis_M","userId":"00362259064081137390"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["## create random population,\n","population = tbx.population(n=100)\n","\n","## set fitness,\n","# set_fitness(population)\n","\n","population[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DmK4z6xFWxZ7","executionInfo":{"status":"ok","timestamp":1653586274456,"user_tz":-180,"elapsed":284,"user":{"displayName":"Orestis_M","userId":"00362259064081137390"}},"outputId":"1b8d99fb-e0dc-4e59-ecd3-96ef8bd0edf2"},"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0],\n"," [1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n"," [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n"," [1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1],\n"," [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0]]"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["evaluation = tbx.evaluate(df2.importance)\n","\n","evaluation\n","\n","fitnessValues = list(map(tbx.evaluate, population))\n","\n","fitnessValues[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_nX6nyPCZqDe","executionInfo":{"status":"ok","timestamp":1653586625815,"user_tz":-180,"elapsed":315,"user":{"displayName":"Orestis_M","userId":"00362259064081137390"}},"outputId":"6c969d77-7450-49d1-a9c6-4cdc760eacd6"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.55, 0.55, 0.35, 0.5, 0.6]"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["iteration = 1\n","while iteration < 100:\n","    \n","    current_population = list(map(tbx.clone, population))\n","    \n","    offspring = []\n","    for _ in range(10):\n","      i1, i2 = np.random.choice(range(len(population)), size=2, replace=False)   \n","      offspring1, offspring2 = tbx.mate(population[i1], population[i2])  \n","      offspring.append(tbx.mutate(offspring1)[0])\n","      offspring.append(tbx.mutate(offspring2)[0])  \n","    \n","    for child in offspring:\n","        current_population.append(child)    \n","    \n","    ## reset fitness,\n","    set_fitness(current_population)   \n","    ## tourn. select, \n","    population[:] = tbx.select(current_population, len(population))\n","    \n","    iteration += 1"],"metadata":{"id":"3i45d0AwXbs4","executionInfo":{"status":"error","timestamp":1653586236154,"user_tz":-180,"elapsed":274,"user":{"displayName":"Orestis_M","userId":"00362259064081137390"}},"colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"14dbd541-af5a-4d30-db9f-a26920e3e0b8"},"execution_count":81,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-81-f0b3ca88c32d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0moffspring1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffspring2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0moffspring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffspring1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0moffspring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffspring2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Toolbox' object has no attribute 'mate'"]}]}]}